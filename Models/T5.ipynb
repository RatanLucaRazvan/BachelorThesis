{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPA7xnwV8vUJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        ")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#EXPERIMENT ONE\n",
        "\n",
        "drive.mount('/drive')\n",
        "df = pd.read_csv(\"/drive/My Drive/dataset_experiment_one.csv\")\n",
        "df[\"label\"] = df[\"tag\"].map({\"real_news\": \"real\", \"fake_news\": \"fals\"})\n",
        "df[\"input_text\"] = \"clasifică știre: \" + df[\"content\"]\n",
        "\n",
        "\n",
        "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
        "    df[\"input_text\"], df[\"label\"], test_size=0.2, stratify=df[\"label\"], random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
        "    temp_texts, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
        ")\n",
        "\n",
        "model_name = \"t5-base\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "class T5NewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
        "        self.inputs = tokenizer(list(texts), max_length=max_len, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        self.targets = tokenizer(list(labels), max_length=10, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.inputs.items()}\n",
        "        item[\"labels\"] = self.targets[\"input_ids\"][idx]\n",
        "        item[\"labels\"][item[\"labels\"] == tokenizer.pad_token_id] = -100\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs[\"input_ids\"])\n",
        "\n",
        "train_dataset = T5NewsDataset(train_texts, train_labels, tokenizer)\n",
        "test_dataset  = T5NewsDataset(test_texts, test_labels, tokenizer)\n",
        "val_dataset   = T5NewsDataset(val_texts, val_labels, tokenizer)\n",
        "\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(decoded_labels, decoded_preds),\n",
        "        \"precision\": precision_score(decoded_labels, decoded_preds, average=\"weighted\"),\n",
        "        \"recall\": recall_score(decoded_labels, decoded_preds, average=\"weighted\"),\n",
        "        \"f1\": f1_score(decoded_labels, decoded_preds, average=\"weighted\"),\n",
        "    }\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"/drive/My Drive/results_t5_experiment_one\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=3e-4,\n",
        "    weight_decay=0.2,\n",
        "    logging_dir=\"/drive/My Drive/logs_t5_experiment_one,\n",
        "    load_best_model_at_end=True,\n",
        "    predict_with_generate=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "def classify_news(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    output = model.generate(**inputs, max_length=10)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True).strip().lower()\n",
        "\n",
        "y_true = list(test_labels)\n",
        "y_pred = [classify_news(t) for t in test_texts]\n",
        "print(y_pred)\n",
        "y_pred = [pred.lower() for pred in y_pred]\n",
        "\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=[\"fals\", \"real\"]))\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"Precision:\", precision_score(y_true, y_pred, average=\"weighted\"))\n",
        "print(\"Recall:\", recall_score(y_true, y_pred, average=\"weighted\"))\n",
        "print(\"F1 Score:\", f1_score(y_true, y_pred, average=\"weighted\"))\n",
        "\n",
        "def plot_confusion(y_true, y_pred, labels=[\"real\", \"fals\"]):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion(y_true, y_pred)\n",
        "\n",
        "model.save_pretrained(\"/drive/My Drive/t5_experiment_one\")\n",
        "tokenizer.save_pretrained(\"/drive/My Drive/t5_experiment_one\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        ")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#EXPERIMENT TWO\n",
        "\n",
        "drive.mount('/drive')\n",
        "train_df = pd.read_csv(\"/drive/My Drive/dataset_experiment_two_training.csv\")\n",
        "test_df = pd.read_csv(\"/drive/My Drive/dataset_experiment_two_testing.csv\")\n",
        "\n",
        "\n",
        "train_df[\"label\"] = train_df[\"tag\"].map({\"real_news\": \"real\", \"fake_news\": \"fals\"})\n",
        "test_df[\"label\"] = test_df[\"tag\"].map({\"real_news\": \"real\", \"fake_news\": \"fals\"})\n",
        "\n",
        "train_df[\"input_text\"] = \"clasifică știre: \" + train_df[\"content\"]\n",
        "test_df[\"input_text\"] = \"clasifică știre: \" + test_df[\"content\"]\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    train_df[\"input_text\"], train_df[\"label\"], test_size=0.1, stratify=train_df[\"label\"], random_state=42\n",
        ")\n",
        "\n",
        "test_texts = test_df[\"input_text\"]\n",
        "test_labels = test_df[\"label\"]\n",
        "\n",
        "\n",
        "model_name = \"t5-base\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "class T5NewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
        "        self.inputs = tokenizer(list(texts), max_length=max_len, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        self.targets = tokenizer(list(labels), max_length=10, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.inputs.items()}\n",
        "        item[\"labels\"] = self.targets[\"input_ids\"][idx]\n",
        "        item[\"labels\"][item[\"labels\"] == tokenizer.pad_token_id] = -100  # Ignore pad tokens in loss\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs[\"input_ids\"])\n",
        "\n",
        "train_dataset = T5NewsDataset(train_texts, train_labels, tokenizer)\n",
        "test_dataset  = T5NewsDataset(test_texts, test_labels, tokenizer)\n",
        "val_dataset   = T5NewsDataset(val_texts, val_labels, tokenizer)\n",
        "\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(decoded_labels, decoded_preds),\n",
        "        \"precision\": precision_score(decoded_labels, decoded_preds, average=\"weighted\"),\n",
        "        \"recall\": recall_score(decoded_labels, decoded_preds, average=\"weighted\"),\n",
        "        \"f1\": f1_score(decoded_labels, decoded_preds, average=\"weighted\"),\n",
        "    }\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"/drive/My Drive/results_t5_experiment_two\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=10,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.1,\n",
        "    logging_dir=\"/drive/My Drive/logs_t5_experiment_two\",\n",
        "    load_best_model_at_end=True,\n",
        "    predict_with_generate=True,\n",
        "    metric_for_best_model=\"accuracy\"\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "def classify_news(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    output = model.generate(**inputs, max_length=10)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True).strip().lower()\n",
        "\n",
        "y_true = list(test_labels)\n",
        "y_pred = [classify_news(t) for t in test_texts]\n",
        "print(y_pred)\n",
        "y_pred = [pred.lower() for pred in y_pred]\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=[\"fals\", \"real\"]))\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"Precision:\", precision_score(y_true, y_pred, average=\"weighted\"))\n",
        "print(\"Recall:\", recall_score(y_true, y_pred, average=\"weighted\"))\n",
        "print(\"F1 Score:\", f1_score(y_true, y_pred, average=\"weighted\"))\n",
        "\n",
        "def plot_confusion(y_true, y_pred, labels=[\"real\", \"fals\"]):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion(y_true, y_pred)\n",
        "\n",
        "model.save_pretrained(\"/drive/My Drive/t5_experiment_two\")\n",
        "tokenizer.save_pretrained(\"/drive/My Drive/t5_experiment_two\")\n"
      ],
      "metadata": {
        "id": "fwBwQG4h9mJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        ")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#EXPERIMENT THREE\n",
        "\n",
        "drive.mount('/drive')\n",
        "df = pd.read_csv(\"/drive/My Drive/dataset_experiment_three.csv\")\n",
        "df[\"label\"] = df[\"tag\"].map({\"real_news\": \"real\", \"fake_news\": \"fals\"})\n",
        "df[\"input_text\"] = \"clasifică știre: \" + df[\"content\"]\n",
        "\n",
        "\n",
        "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
        "    df[\"input_text\"], df[\"label\"], test_size=0.2, stratify=df[\"label\"], random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
        "    temp_texts, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
        ")\n",
        "\n",
        "model_name = \"t5-base\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "class T5NewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
        "        self.inputs = tokenizer(list(texts), max_length=max_len, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        self.targets = tokenizer(list(labels), max_length=10, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.inputs.items()}\n",
        "        item[\"labels\"] = self.targets[\"input_ids\"][idx]\n",
        "        item[\"labels\"][item[\"labels\"] == tokenizer.pad_token_id] = -100\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs[\"input_ids\"])\n",
        "\n",
        "train_dataset = T5NewsDataset(train_texts, train_labels, tokenizer)\n",
        "test_dataset  = T5NewsDataset(test_texts, test_labels, tokenizer)\n",
        "val_dataset   = T5NewsDataset(val_texts, val_labels, tokenizer)\n",
        "\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(decoded_labels, decoded_preds),\n",
        "        \"precision\": precision_score(decoded_labels, decoded_preds, average=\"weighted\"),\n",
        "        \"recall\": recall_score(decoded_labels, decoded_preds, average=\"weighted\"),\n",
        "        \"f1\": f1_score(decoded_labels, decoded_preds, average=\"weighted\"),\n",
        "    }\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"/drive/My Drive/results_t5_experiment_three\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=10,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.0,\n",
        "    logging_dir=\"/drive/My Drive/logs_t5_experiment_three\",\n",
        "    load_best_model_at_end=True,\n",
        "    predict_with_generate=True,\n",
        "    metric_for_best_model=\"accuracy\"\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "def classify_news(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    output = model.generate(**inputs, max_length=10)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True).strip().lower()\n",
        "\n",
        "y_true = list(test_labels)\n",
        "y_pred = [classify_news(t) for t in test_texts]\n",
        "print(y_pred)\n",
        "y_pred = [pred.lower() for pred in y_pred]\n",
        "\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=[\"fals\", \"real\"]))\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"Precision:\", precision_score(y_true, y_pred, average=\"weighted\"))\n",
        "print(\"Recall:\", recall_score(y_true, y_pred, average=\"weighted\"))\n",
        "print(\"F1 Score:\", f1_score(y_true, y_pred, average=\"weighted\"))\n",
        "\n",
        "def plot_confusion(y_true, y_pred, labels=[\"real\", \"fals\"]):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion(y_true, y_pred)\n",
        "\n",
        "model.save_pretrained(\"/drive/My Drive/t5_experiment_three\")\n",
        "tokenizer.save_pretrained(\"/drive/My Drive/t5_experiment_three\")\n"
      ],
      "metadata": {
        "id": "58IrLURb9mor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from transformers import (\n",
        "    T5Tokenizer, T5ForConditionalGeneration,\n",
        "    Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        ")\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#EXPERIMENT FOUR\n",
        "drive.mount('/drive')\n",
        "\n",
        "df = pd.read_json(\"hf://datasets/mihalca/FakeRO_updated/combined_balanced.json\")\n",
        "df[\"label\"] = df[\"tag\"].map({\n",
        "    \"real_news\": \"real\",\n",
        "    \"fake_news\": \"fals\",\n",
        "    \"propaganda\": \"propagandă\",\n",
        "    \"satire\": \"satiră\",\n",
        "    \"misinformation\": \"dezinformare\"\n",
        "})\n",
        "df[\"input_text\"] = \"clasifică știre: \" + df[\"content\"]\n",
        "\n",
        "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
        "    df[\"input_text\"], df[\"label\"], test_size=0.2, stratify=df[\"label\"], random_state=42\n",
        ")\n",
        "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
        "    temp_texts, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
        ")\n",
        "\n",
        "model_name=\"t5-base\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "class T5NewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
        "        self.inputs = tokenizer(list(texts), max_length=max_len, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        self.targets = tokenizer(list(labels), max_length=10, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.inputs.items()}\n",
        "        item[\"labels\"] = self.targets[\"input_ids\"][idx]\n",
        "        item[\"labels\"][item[\"labels\"] == tokenizer.pad_token_id] = -100\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs[\"input_ids\"])\n",
        "\n",
        "train_dataset = T5NewsDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = T5NewsDataset(val_texts, val_labels, tokenizer)\n",
        "test_dataset = T5NewsDataset(test_texts, test_labels, tokenizer)\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(decoded_labels, decoded_preds),\n",
        "        \"precision\": precision_score(decoded_labels, decoded_preds, average=\"macro\"),\n",
        "        \"recall\": recall_score(decoded_labels, decoded_preds, average=\"macro\"),\n",
        "        \"f1\": f1_score(decoded_labels, decoded_preds, average=\"macro\"),\n",
        "    }\n",
        "\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"/drive/My Drive/results_t5_experiment_four\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=10,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.1,\n",
        "    logging_dir=\"/drive/My Drive/logs_t5_experiment_four\",\n",
        "    load_best_model_at_end=True,\n",
        "    predict_with_generate=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "def classify_news(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    output = trainer.model.generate(**inputs, max_length=10)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True).strip().lower()\n",
        "\n",
        "y_true = list(test_labels)\n",
        "y_pred = [classify_news(t) for t in test_texts]\n",
        "y_pred = [pred.lower() for pred in y_pred]\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=[\"real\", \"fals\", \"propagandă\", \"satiră\", \"dezinformare\"]))\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"Precision:\", precision_score(y_true, y_pred, average=\"macro\"))\n",
        "print(\"Recall:\", recall_score(y_true, y_pred, average=\"macro\"))\n",
        "print(\"F1 Score:\", f1_score(y_true, y_pred, average=\"macro\"))\n",
        "\n",
        "def plot_confusion(y_true, y_pred, labels=[\"fals\", \"dezinformare\", \"propagandă\", \"real\", \"satiră\"]):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion(y_true, y_pred)\n",
        "\n",
        "model.save_pretrained(\"/drive/My Drive/t5_experiment_four\")\n",
        "tokenizer.save_pretrained(\"/drive/My Drive/t5_experiment_four\")\n"
      ],
      "metadata": {
        "id": "i60iF3-K9m15"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}